# Insurance Chatbot - CIB HackIdea

An end-to-end insurance chatbot application with RAG (Retrieval-Augmented Generation) that supports both text and audio interactions. The chatbot can answer questions about insurance policies (health, car, bike) and suggest relevant policies based on user queries.

## ğŸ¯ Features

- **Text Chat**: Ask questions via text input
- **Audio Chat**: Record audio questions and receive audio responses with real-time transcription
- **RAG Pipeline**: Uses FAISS vector store and semantic search for accurate answers
- **GPT-4 Integration**: Uses GPT-4 with strict anti-hallucination controls
- **OpenAI Whisper STT**: Real-time speech-to-text transcription (auto-enabled with API key)
- **Policy Suggestions**: Automatically suggests relevant insurance policies with website links
- **Source Citations**: Shows which policy documents were used to generate answers
- **Conversation Memory**: Maintains context across multiple messages in a session
- **Anti-Hallucination**: Configured to prevent making up information, only uses provided context

---

## ğŸ—ï¸ Architecture

### System Overview

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         FRONTEND (React)                        â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”‚
â”‚  â”‚   Chat UI    â”‚  â”‚ AudioRecorderâ”‚  â”‚  Message     â”‚         â”‚
â”‚  â”‚              â”‚  â”‚              â”‚  â”‚  Display     â”‚         â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜         â”‚
â”‚         â”‚                 â”‚                 â”‚                  â”‚
â”‚         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                  â”‚
â”‚                           â”‚                                    â”‚
â”‚                    HTTP/REST API                                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚
                            â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    BACKEND (FastAPI)                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚                    API Endpoints                          â”‚  â”‚
â”‚  â”‚  â€¢ GET  /health                                           â”‚  â”‚
â”‚  â”‚  â€¢ POST /api/chat-text                                    â”‚  â”‚
â”‚  â”‚  â€¢ POST /api/chat-audio                                   â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                            â”‚                                    â”‚
â”‚         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”              â”‚
â”‚         â”‚                                       â”‚              â”‚
â”‚         â–¼                                       â–¼              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”‚
â”‚  â”‚ STT Service  â”‚                      â”‚ TTS Service  â”‚       â”‚
â”‚  â”‚ (Whisper/   â”‚                      â”‚ (Mock/Polly) â”‚       â”‚
â”‚  â”‚  Mock)      â”‚                      â”‚              â”‚       â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â”‚
â”‚         â”‚                                       â”‚              â”‚
â”‚         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜              â”‚
â”‚                             â”‚                                  â”‚
â”‚                             â–¼                                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚              RAG Pipeline                                â”‚  â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚  â”‚
â”‚  â”‚  â”‚  Retrieval  â”‚â†’ â”‚  LLM Chain    â”‚â†’ â”‚  Policy       â”‚ â”‚  â”‚
â”‚  â”‚  â”‚  (FAISS)    â”‚  â”‚  (GPT-4)     â”‚  â”‚  Suggester    â”‚ â”‚  â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                             â”‚                                   â”‚
â”‚                             â–¼                                   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚         Conversation Memory (In-Memory Sessions)          â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚
                            â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    DATA LAYER                                   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”‚
â”‚  â”‚  Policy      â”‚  â”‚  FAISS       â”‚  â”‚  Embeddings  â”‚         â”‚
â”‚  â”‚  Documents   â”‚  â”‚  Vector      â”‚  â”‚  (Sentence  â”‚         â”‚
â”‚  â”‚  (JSON)      â”‚  â”‚  Index       â”‚  â”‚  Transformers)â”‚       â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Component Architecture

#### Backend Components

1. **FastAPI Application (`main.py`)**
   - RESTful API endpoints
   - Request/response handling
   - Error handling and validation
   - CORS middleware
   - Static file serving for audio

2. **RAG Pipeline**
   - **Ingestion (`rag/ingest.py`)**: Loads, chunks, and indexes policy documents
   - **Retrieval (`rag/retrieval.py`)**: Semantic search using FAISS
   - **LLM Chain (`rag/llm_chain.py`)**: GPT-4 integration with RAG context

3. **Services**
   - **STT Service (`services/stt_service.py`)**: Speech-to-text (Whisper/Mock)
   - **TTS Service (`services/tts_service.py`)**: Text-to-speech (Mock/Polly)
   - **Policy Suggester (`services/policy_suggester.py`)**: Suggests relevant policies
   - **Conversation Memory (`services/conversation_memory.py`)**: Session management

4. **Data Models (`models/schemas.py`)**
   - Pydantic models for request/response validation
   - Type-safe data structures

#### Frontend Components

1. **Chat Component (`components/Chat.jsx`)**
   - Main chat interface
   - Message history display
   - Text input handling
   - Policy suggestions display
   - Source citations

2. **Audio Recorder (`components/AudioRecorder.jsx`)**
   - Browser MediaRecorder API integration
   - Audio recording and playback
   - Upload to backend

---

## ğŸ”„ System Flow

### Text Chat Flow

```
User Types Message
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Frontend       â”‚
â”‚  (Chat.jsx)     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚ POST /api/chat-text
         â”‚ {message, session_id}
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Backend (main.py)              â”‚
â”‚  1. Get/Create Session          â”‚
â”‚  2. Get Conversation History    â”‚
â”‚  3. Add User Message to History â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Retrieval (retrieval.py)       â”‚
â”‚  1. Embed User Query            â”‚
â”‚  2. FAISS Similarity Search     â”‚
â”‚  3. Filter by Metadata          â”‚
â”‚  4. Return Top-K Chunks         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  LLM Chain (llm_chain.py)       â”‚
â”‚  1. Format Context from Chunks  â”‚
â”‚  2. Build System + User Prompt  â”‚
â”‚  3. Call GPT-4 API              â”‚
â”‚  4. Parse Response               â”‚
â”‚  5. Fallback if Empty/Error     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Policy Suggester               â”‚
â”‚  1. Score Policies by Relevance â”‚
â”‚  2. Return Top 3 Suggestions    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Format Response                â”‚
â”‚  â€¢ Answer Text                  â”‚
â”‚  â€¢ Policy Suggestions           â”‚
â”‚  â€¢ Source Citations             â”‚
â”‚  â€¢ Session ID                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Add Assistant Response         â”‚
â”‚  to Conversation History        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Return JSON Response           â”‚
â”‚  to Frontend                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Frontend Displays              â”‚
â”‚  â€¢ Bot Response                 â”‚
â”‚  â€¢ Policy Suggestions           â”‚
â”‚  â€¢ Source Citations             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Audio Chat Flow

```
User Clicks Record
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Frontend (AudioRecorder.jsx)   â”‚
â”‚  1. Request Microphone Access    â”‚
â”‚  2. Start MediaRecorder          â”‚
â”‚  3. Collect Audio Chunks         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â”‚ User Stops Recording
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Create Audio Blob              â”‚
â”‚  Send to /api/chat-audio        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Backend (main.py)              â”‚
â”‚  1. Save Uploaded Audio File    â”‚
â”‚  2. Check File Size              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  STT Service (stt_service.py)   â”‚
â”‚  Auto-detect:                    â”‚
â”‚  â€¢ If OPENAI_API_KEY â†’ Whisper  â”‚
â”‚  â€¢ Else â†’ Mock STT              â”‚
â”‚  Returns: Transcript            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Same as Text Chat Flow:        â”‚
â”‚  â€¢ Retrieval                    â”‚
â”‚  â€¢ LLM Chain                    â”‚
â”‚  â€¢ Policy Suggestions           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  TTS Service (tts_service.py)   â”‚
â”‚  Generate Audio from Answer     â”‚
â”‚  Save to data/audio_output/     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Return Response with:          â”‚
â”‚  â€¢ Transcript                    â”‚
â”‚  â€¢ Answer                       â”‚
â”‚  â€¢ Audio URL                    â”‚
â”‚  â€¢ Suggestions                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Frontend:                      â”‚
â”‚  1. Display Transcript          â”‚
â”‚  2. Display Bot Response        â”‚
â”‚  3. Play TTS Audio              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### RAG Pipeline Flow (Detailed)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    INGESTION PHASE                          â”‚
â”‚                    (One-time setup)                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  1. Load Policy Documents (JSON)                            â”‚
â”‚     â€¢ health_policy_1.json                                 â”‚
â”‚     â€¢ car_policy_1.json                                     â”‚
â”‚     â€¢ bike_policy_1.json                                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  2. Chunk Text                                              â”‚
â”‚     â€¢ Split into 500-char chunks                            â”‚
â”‚     â€¢ 50-char overlap                                       â”‚
â”‚     â€¢ Preserve metadata (policy_id, type, region)           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  3. Generate Embeddings                                      â”‚
â”‚     â€¢ Use Sentence Transformers (all-MiniLM-L6-v2)          â”‚
â”‚     â€¢ Convert chunks to 384-dim vectors                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  4. Build FAISS Index                                       â”‚
â”‚     â€¢ Store vectors in FAISS index                          â”‚
â”‚     â€¢ Save metadata separately (pickle)                     â”‚
â”‚     â€¢ Save to data/vector_store/                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    RETRIEVAL PHASE                          â”‚
â”‚                    (Per Query)                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  1. Load FAISS Index & Metadata                             â”‚
â”‚     â€¢ Load from data/vector_store/                          â”‚
â”‚     â€¢ Initialize embedding model                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  2. Embed User Query                                         â”‚
â”‚     â€¢ Same embedding model as documents                     â”‚
â”‚     â€¢ Convert query to 384-dim vector                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  3. Similarity Search                                        â”‚
â”‚     â€¢ FAISS computes cosine similarity                      â”‚
â”‚     â€¢ Retrieve top-k candidates (k * 2 if filters)         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  4. Filter by Metadata                                      â”‚
â”‚     â€¢ Filter by policy_type (if specified)                  â”‚
â”‚     â€¢ Filter by region (if specified)                        â”‚
â”‚     â€¢ Return top-k after filtering                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  5. Return Retrieved Chunks                                 â”‚
â”‚     â€¢ List of RetrievedChunk objects                        â”‚
â”‚     â€¢ Each with: text, policy_id, metadata                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    GENERATION PHASE                          â”‚
â”‚                    (Per Query)                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  1. Check if Chunks Available                                â”‚
â”‚     â€¢ If chunks â†’ Use context mode                          â”‚
â”‚     â€¢ If no chunks â†’ Use general mode                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  2. Build Prompt                                            â”‚
â”‚     â€¢ System Prompt (context-aware or general)              â”‚
â”‚     â€¢ Format retrieved chunks as context                    â”‚
â”‚     â€¢ Include conversation history                          â”‚
â”‚     â€¢ Add user query                                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  3. Call GPT-4 API                                          â”‚
â”‚     â€¢ Send messages array                                   â”‚
â”‚     â€¢ Temperature = 0.0 (deterministic)                     â”‚
â”‚     â€¢ Max tokens = 1200                                      â”‚
â”‚     â€¢ Retry logic (2 retries)                               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  4. Parse & Validate Response                               â”‚
â”‚     â€¢ Extract answer text                                   â”‚
â”‚     â€¢ Check for empty/error responses                       â”‚
â”‚     â€¢ Fallback if needed                                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  5. Return Answer + Metadata                                â”‚
â”‚     â€¢ Answer text                                           â”‚
â”‚     â€¢ Supporting info (mode, small_talk flag)                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ“ Project Structure

```
.
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ main.py                 # FastAPI application entry point
â”‚   â”œâ”€â”€ config.py               # Configuration settings (Pydantic)
â”‚   â”œâ”€â”€ requirements.txt        # Python dependencies
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â””â”€â”€ schemas.py          # Pydantic data models (request/response)
â”‚   â”œâ”€â”€ rag/
â”‚   â”‚   â”œâ”€â”€ ingest.py           # Policy document ingestion & indexing
â”‚   â”‚   â”œâ”€â”€ retrieval.py        # Semantic search retrieval (FAISS)
â”‚   â”‚   â””â”€â”€ llm_chain.py        # LLM + RAG chain (GPT-4 integration)
â”‚   â”œâ”€â”€ services/
â”‚   â”‚   â”œâ”€â”€ stt_service.py      # Speech-to-Text service (Whisper/Mock)
â”‚   â”‚   â”œâ”€â”€ tts_service.py      # Text-to-Speech service (Mock/Polly)
â”‚   â”‚   â”œâ”€â”€ policy_suggester.py # Policy suggestion logic
â”‚   â”‚   â””â”€â”€ conversation_memory.py # Session & conversation history
â”‚   â””â”€â”€ data/
â”‚       â”œâ”€â”€ policies/           # Policy JSON files (input)
â”‚       â”œâ”€â”€ vector_store/       # FAISS index (generated by ingest)
â”‚       â”œâ”€â”€ audio_output/       # TTS audio files (generated)
â”‚       â””â”€â”€ temp_uploads/       # Temporary audio uploads (STT)
â”‚
â””â”€â”€ frontend/
    â”œâ”€â”€ package.json
    â”œâ”€â”€ vite.config.js
    â”œâ”€â”€ index.html
    â””â”€â”€ src/
        â”œâ”€â”€ App.jsx              # Main React app
        â”œâ”€â”€ main.jsx             # React entry point
        â””â”€â”€ components/
            â”œâ”€â”€ Chat.jsx         # Main chat UI component
            â”œâ”€â”€ Chat.css         # Chat styling
            â”œâ”€â”€ AudioRecorder.jsx # Audio recording component
            â””â”€â”€ AudioRecorder.css # Audio recorder styling
```

---

## ğŸš€ Setup Instructions

### Prerequisites

- Python 3.8 or higher
- Node.js 16 or higher
- npm or yarn
- OpenAI API key (for GPT-4 and Whisper - optional but recommended)

### Backend Setup

1. **Navigate to backend directory:**
   ```bash
   cd backend
   ```

2. **Create a virtual environment (recommended):**
   ```bash
   python -m venv venv
   source venv/bin/activate  # On Windows: venv\Scripts\activate
   ```

3. **Install dependencies:**
   ```bash
   pip install -r requirements.txt
   ```

4. **Set up GPT-4 and Whisper (Recommended):**
   
   Get your OpenAI API key from https://platform.openai.com/
   
   **Set environment variable:**
   ```bash
   export OPENAI_API_KEY="sk-your-key-here"  # Linux/Mac
   # OR
   set OPENAI_API_KEY=sk-your-key-here  # Windows
   ```
   
   **Or create `.env` file in `backend/` directory:**
   ```env
   OPENAI_API_KEY=sk-your-key-here
   ```
   
   See `backend/SETUP_GPT4.md` for detailed instructions.

5. **Run the ingestion pipeline to build the vector index:**
   ```bash
   python -m rag.ingest
   ```
   
   This will:
   - Load policy documents from `data/policies/`
   - Chunk and embed the documents
   - Build a FAISS vector index
   - Save the index to `data/vector_store/`

6. **Start the FastAPI server:**
   ```bash
   python main.py
   ```
   
   Or using uvicorn directly:
   ```bash
   uvicorn main:app --reload --host 0.0.0.0 --port 8000
   ```
   
   The API will be available at `http://localhost:8000`

### Frontend Setup

1. **Navigate to frontend directory:**
   ```bash
   cd frontend
   ```

2. **Install dependencies:**
   ```bash
   npm install
   ```

3. **Start the development server:**
   ```bash
   npm run dev
   ```
   
   The frontend will be available at `http://localhost:3000` (or the port shown)

---

## ğŸ’¬ Usage

### Text Chat

1. Type your question in the text input field
2. Click "Send" or press Enter
3. View the bot's response with:
   - Answer text
   - Suggested policies (with website links)
   - Source citations (click "View Sources" to expand)

### Audio Chat

1. Click the "Record Audio" button
2. Speak your question (microphone permission required)
3. Click "Stop Recording" when done
4. The bot will:
   - Transcribe your audio (using Whisper if API key is set)
   - Process the question through RAG pipeline
   - Return a text answer
   - Generate and play audio response (mock TTS for now)

### Example Questions

- "What is covered under my health insurance policy?"
- "What are the exclusions in car insurance?"
- "What is the maximum coverage limit for bike insurance?"
- "Does my health policy cover pre-existing conditions?"
- "What is the deductible for car insurance?"
- "I need health insurance for a 57 year old male"
- "Compare health and car insurance"

---

## âš™ï¸ Configuration

### Environment Variables

Create a `.env` file in the `backend/` directory:

```env
# Required for GPT-4 LLM and Whisper STT
OPENAI_API_KEY=your-key-here

# Optional: STT/TTS providers
STT_PROVIDER=auto  # Options: auto, mock, openai-whisper
TTS_PROVIDER=mock  # Options: mock, amazon-polly, google-tts
```

**Note**: 
- `STT_PROVIDER=auto` automatically uses Whisper if `OPENAI_API_KEY` is set
- If `OPENAI_API_KEY` is not set, the system falls back to Mock LLM and Mock STT
- See `backend/SETUP_GPT4.md` for detailed setup instructions

### Backend Configuration

Edit `backend/config.py` to adjust:
- Chunk size and overlap for document chunking
- Number of retrieved chunks (k)
- Embedding model
- STT/TTS providers
- LLM model and temperature

---

## ğŸ”Œ API Endpoints

### `GET /health`
Health check endpoint.

**Response:**
```json
{"status": "ok"}
```

### `POST /api/chat-text`
Text-based chat endpoint.

**Request:**
```json
{
  "message": "What is covered under health insurance?",
  "session_id": "optional-session-id",
  "policy_type": "health",
  "region": "US"
}
```

**Response:**
```json
{
  "answer": "Based on the available policy documents...",
  "policy_suggestions": [
    {
      "policy_id": "health_policy_1",
      "policy_type": "health",
      "title": "Comprehensive Health Insurance Plan",
      "reason": "Highly relevant based on 3 matching clauses",
      "website_url": "https://example.com/health-policy-1"
    }
  ],
  "sources": [
    {
      "policy_id": "health_policy_1",
      "policy_type": "health",
      "clause_type": "coverage",
      "text_snippet": "Health insurance covers..."
    }
  ],
  "session_id": "generated-session-id"
}
```

### `POST /api/chat-audio`
Audio-based chat endpoint.

**Request:**
- `multipart/form-data` with `audio_file` field
- Optional: `session_id` form field

**Response:**
```json
{
  "transcript": "What is covered under health insurance?",
  "answer": "...",
  "policy_suggestions": [...],
  "sources": [...],
  "audio_url": "/audio/response.wav",
  "session_id": "generated-session-id"
}
```

---

## ğŸ› ï¸ Adding Real STT/TTS Providers

### Speech-to-Text (STT)

The code includes implementations for:
- âœ… **OpenAI Whisper** (auto-enabled with API key)
- âš ï¸ Google Cloud Speech-to-Text (placeholder)

**Whisper is automatically used if `OPENAI_API_KEY` is set!**

To use Google Speech:
1. Uncomment the function in `services/stt_service.py`
2. Install: `pip install google-cloud-speech`
3. Set `STT_PROVIDER="google-speech"` in config
4. Configure Google Cloud credentials

### Text-to-Speech (TTS)

The code includes placeholder functions for:
- Amazon Polly
- Google Cloud Text-to-Speech

To implement:
1. Uncomment the relevant function in `services/tts_service.py`
2. Install the required SDK (e.g., `pip install boto3`)
3. Set the `TTS_PROVIDER` environment variable
4. Configure credentials

---

## ğŸ› Troubleshooting

### Backend Issues

1. **FAISS index not found:**
   ```bash
   cd backend
   python -m rag.ingest
   ```

2. **Import errors:**
   - Ensure you're in the backend directory
   - Activate your virtual environment
   - Install all dependencies: `pip install -r requirements.txt`

3. **Port already in use:**
   - Change the port in `config.py` or use: `uvicorn main:app --port 8001`

4. **GPT-4 not working:**
   - Check `OPENAI_API_KEY` is set: `echo $OPENAI_API_KEY`
   - Verify API key is valid
   - Check backend logs for error messages
   - See `backend/SETUP_GPT4.md` for detailed troubleshooting

5. **Whisper transcription not working:**
   - Ensure `OPENAI_API_KEY` is set
   - Check backend logs for transcription errors
   - Verify audio file is being uploaded (check file size in logs)

### Frontend Issues

1. **Cannot connect to backend:**
   - Ensure backend is running on port 8000
   - Check CORS settings in `backend/main.py`
   - Verify `API_BASE_URL` in frontend components

2. **Microphone not working:**
   - Check browser permissions (Chrome: Settings â†’ Privacy â†’ Microphone)
   - Use HTTPS or localhost (required for getUserMedia)
   - Try a different browser

3. **Audio playback issues:**
   - Check browser console for errors
   - Ensure backend audio files are accessible at `/audio/` endpoint
   - Verify TTS service is generating files

---

## ğŸ“Š Data Flow Summary

1. **Ingestion** (One-time): Documents â†’ Chunks â†’ Embeddings â†’ FAISS Index
2. **Query** (Per request): User Input â†’ Embed Query â†’ Search FAISS â†’ Retrieve Chunks
3. **Generation**: Chunks + Query â†’ LLM Prompt â†’ GPT-4 â†’ Answer
4. **Enhancement**: Answer + Chunks â†’ Policy Suggestions + Sources
5. **Response**: Answer + Suggestions + Sources â†’ Frontend Display

---

## ğŸ” Security Notes

- API keys should never be committed to version control
- Use environment variables or `.env` files (add `.env` to `.gitignore`)
- CORS is configured for local development only
- For production, implement proper authentication and rate limiting

---

## ğŸ“ Development Notes

- The mock STT service returns a generic transcript for demo purposes
- The mock TTS service creates a placeholder WAV file (silence)
- For production, replace mocks with real API integrations
- All code includes detailed comments explaining functionality
- Conversation memory is stored in-memory (not persistent across server restarts)

---

## ğŸ“ Key Technologies

- **Backend**: FastAPI, Python 3.9+
- **RAG**: FAISS, Sentence Transformers
- **LLM**: OpenAI GPT-4
- **STT**: OpenAI Whisper (auto-enabled)
- **Frontend**: React, Vite
- **Audio**: Browser MediaRecorder API

---

## ğŸ“š Additional Documentation

- `backend/SETUP_GPT4.md` - Detailed GPT-4 setup guide
- `backend/LLM_INFO.md` - LLM configuration information
- `AUDIO_FIX_SUMMARY.md` - Audio transcription fixes
- `TESTING_GUIDE.md` - Testing instructions

---

## ğŸ“„ License

This project is provided as-is for educational and development purposes.

---

## ğŸ¤ Contributing

Feel free to extend this project with:
- Additional policy types
- More sophisticated policy suggestion algorithms
- Real TTS provider integrations
- Persistent conversation storage (database)
- User authentication
- Database integration for policies
- Multi-language support

---

## ğŸ‰ Quick Start Summary

```bash
# Backend
cd backend
python -m venv venv
source venv/bin/activate
pip install -r requirements.txt
export OPENAI_API_KEY="sk-your-key"  # Optional but recommended
python -m rag.ingest  # Build vector index
python main.py  # Start server

# Frontend (in new terminal)
cd frontend
npm install
npm run dev
```

Open `http://localhost:3000` and start chatting! ğŸš€
